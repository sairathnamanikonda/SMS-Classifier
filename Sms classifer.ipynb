{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adb39201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa9aa15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data\n",
    "df = pd.read_csv(\"C:/Users/manoj/Downloads/spam.csv\",encoding='latin-1')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b234acbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Text</th>\n",
       "      <th>label_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               Text  label_enc\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0\n",
       "1   ham                      Ok lar... Joking wif u oni...          0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
       "3   ham  U dun say so early hor... U c already then say...          0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1)\n",
    "df = df.rename(columns={'v1':'label','v2':'Text'})\n",
    "df['label_enc'] = df['label'].map({'ham':0,'spam':1})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "968bc79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEHCAYAAABfkmooAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAARsUlEQVR4nO3dfZBdd13H8feHtJQKFNvptpZsNR2Mjm0RMGusMD7wMBJFTUWKYcBmtGOYWgUdR22dEVEnigo+8NDORK1JRa0RxAa1YI2goqVlI4U0LZUMLW1MbAKoFB8qab/+cX+ZXpJtflvcc3fTfb9m7pxzvuecu9/N3Mlnz9PvpqqQJOl4nrDYDUiSlj7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXScN+eZJ7gEeAB4CDlfVTJIzgD8GVgH3AC+vqn9r218FXNa2f01VvbfV1wBbgVOBvwReW517fs8888xatWrVgv9OkvR4tmvXrk9V1dTR9UHDonl+VX1qbPlKYGdVvSHJlW35p5OcD2wALgCeDvx1kq+qqoeAa4BNwAcZhcU64Mbj/dBVq1YxOzu78L+NJD2OJfnkXPXFOA21HtjW5rcBF4/Vr6+qB6vqbmAvsDbJOcBpVXVzO5q4bmwfSdIEDB0WBfxVkl1JNrXa2VV1AKBNz2r1lcB9Y/vua7WVbf7o+jGSbEoym2T20KFDC/hrSNLyNvRpqOdV1f4kZwE3JfnYcbbNHLU6Tv3YYtUWYAvAzMyM45hI0gIZ9Miiqva36UHgXcBa4P52aok2Pdg23wecO7b7NLC/1afnqEuSJmSwsEjy5CRPPTIPfBtwO7AD2Ng22wjc0OZ3ABuSnJLkPGA1cGs7VfVAkouSBLh0bB9J0gQMeRrqbOBdo//fOQn4w6p6T5IPAduTXAbcC1wCUFV7kmwH7gAOA1e0O6EALueRW2dvpHMnlCRpYeXxOkT5zMxMeeusJD02SXZV1czRdZ/gliR1GRaSpK5JPMF9Qlrzk9ctdgtagnb92qWL3YK0KDyykCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYOHRZIVST6c5M/b8hlJbkry8TY9fWzbq5LsTXJXkheP1dck2d3WvTlJhu5bkvSISRxZvBa4c2z5SmBnVa0GdrZlkpwPbAAuANYBVydZ0fa5BtgErG6vdRPoW5LUDBoWSaaBlwC/M1ZeD2xr89uAi8fq11fVg1V1N7AXWJvkHOC0qrq5qgq4bmwfSdIEDH1k8ZvATwEPj9XOrqoDAG16VquvBO4b225fq61s80fXj5FkU5LZJLOHDh1akF9AkjRgWCT5TuBgVe2a7y5z1Oo49WOLVVuqaqaqZqampub5YyVJPScN+N7PA747yXcATwJOS/J24P4k51TVgXaK6WDbfh9w7tj+08D+Vp+eoy5JmpDBjiyq6qqqmq6qVYwuXP9NVb0K2AFsbJttBG5o8zuADUlOSXIeowvZt7ZTVQ8kuajdBXXp2D6SpAkY8sji0bwB2J7kMuBe4BKAqtqTZDtwB3AYuKKqHmr7XA5sBU4FbmwvSdKETCQsqur9wPvb/KeBFz7KdpuBzXPUZ4ELh+tQknQ8PsEtSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2DhUWSJyW5NclHkuxJ8vOtfkaSm5J8vE1PH9vnqiR7k9yV5MVj9TVJdrd1b06SofqWJB1ryCOLB4EXVNWzgGcD65JcBFwJ7Kyq1cDOtkyS84ENwAXAOuDqJCvae10DbAJWt9e6AfuWJB1lsLCokc+1xZPbq4D1wLZW3wZc3ObXA9dX1YNVdTewF1ib5BzgtKq6uaoKuG5sH0nSBAx6zSLJiiS3AQeBm6rqFuDsqjoA0KZntc1XAveN7b6v1Va2+aPrc/28TUlmk8weOnRoQX8XSVrOBg2Lqnqoqp4NTDM6SrjwOJvPdR2ijlOf6+dtqaqZqpqZmpp6zP1KkuY2kbuhqurfgfczutZwfzu1RJsebJvtA84d220a2N/q03PUJUkTMuTdUFNJvrTNnwq8CPgYsAPY2DbbCNzQ5ncAG5KckuQ8Rheyb22nqh5IclG7C+rSsX0kSRNw0oDvfQ6wrd3R9ARge1X9eZKbge1JLgPuBS4BqKo9SbYDdwCHgSuq6qH2XpcDW4FTgRvbS5I0IYOFRVV9FHjOHPVPAy98lH02A5vnqM8Cx7veIUkakE9wS5K6DAtJUpdhIUnqmldYJNk5n5ok6fHpuBe4kzwJ+BLgzDbg35EH5E4Dnj5wb5KkJaJ3N9SrgR9jFAy7eCQsPgu8bbi2JElLyXHDoqp+C/itJD9aVW+ZUE+SpCVmXs9ZVNVbkjwXWDW+T1VdN1BfkqQlZF5hkeT3gWcAtwFHnqo+Mly4JOlxbr5PcM8A57fvk5AkLTPzfc7iduDLhmxEkrR0zffI4kzgjiS3Mvq6VACq6rsH6UqStKTMNyxeP2QTkqSlbb53Q/3t0I1Ikpau+d4N9QCPfJXpE4GTgf+sqtOGakyStHTM98jiqePLSS4G1g7RkCRp6fmiRp2tqj8DXrCwrUiSlqr5noZ66djiExg9d+EzF5K0TMz3bqjvGps/DNwDrF/wbiRJS9J8r1n8wNCNSJKWrvl++dF0knclOZjk/iTvTDI9dHOSpKVhvhe4fw/Yweh7LVYC7241SdIyMN+wmKqq36uqw+21FZgasC9J0hIy37D4VJJXJVnRXq8CPj1kY5KkpWO+YfGDwMuBfwUOAC8DvOgtScvEfG+d/UVgY1X9G0CSM4A3MgoRSdLj3HyPLL72SFAAVNVngOcM05IkaamZb1g8IcnpRxbakcV8j0okSSe4+f6H/ybgH5O8g9EwHy8HNg/WlSRpSZnvE9zXJZllNHhggJdW1R2DdiZJWjLmfSqphYMBIUnL0Bc1RLkkaXkxLCRJXYaFJKlrsLBIcm6S9yW5M8meJK9t9TOS3JTk4206fkvuVUn2JrkryYvH6muS7G7r3pwkQ/UtSTrWkEcWh4GfqKqvAS4CrkhyPnAlsLOqVgM72zJt3QbgAmAdcHWSFe29rgE2Aavba92AfUuSjjJYWFTVgar6pzb/AHAno+HN1wPb2mbbgIvb/Hrg+qp6sKruBvYCa5OcA5xWVTdXVQHXje0jSZqAiVyzSLKK0fAgtwBnV9UBGAUKcFbbbCVw39hu+1ptZZs/uj7Xz9mUZDbJ7KFDhxb0d5Ck5WzwsEjyFOCdwI9V1WePt+kctTpO/dhi1Zaqmqmqmakpv25DkhbKoGGR5GRGQfEHVfWnrXx/O7VEmx5s9X3AuWO7TwP7W316jrokaUKGvBsqwO8Cd1bVr4+t2gFsbPMbgRvG6huSnJLkPEYXsm9tp6oeSHJRe89Lx/aRJE3AkCPHPg/4fmB3ktta7WeANwDbk1wG3AtcAlBVe5JsZzSkyGHgiqp6qO13ObAVOBW4sb0kSRMyWFhU1QeY+3oDwAsfZZ/NzDGabVXNAhcuXHeSpMfCJ7glSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqWuwsEhybZKDSW4fq52R5KYkH2/T08fWXZVkb5K7krx4rL4mye627s1JMlTPkqS5DXlksRVYd1TtSmBnVa0GdrZlkpwPbAAuaPtcnWRF2+caYBOwur2Ofk9J0sAGC4uq+jvgM0eV1wPb2vw24OKx+vVV9WBV3Q3sBdYmOQc4rapurqoCrhvbR5I0IZO+ZnF2VR0AaNOzWn0lcN/YdvtabWWbP7o+pySbkswmmT106NCCNi5Jy9lSucA913WIOk59TlW1papmqmpmampqwZqTpOVu0mFxfzu1RJsebPV9wLlj200D+1t9eo66JGmCJh0WO4CNbX4jcMNYfUOSU5Kcx+hC9q3tVNUDSS5qd0FdOraPJGlCThrqjZP8EfCtwJlJ9gE/B7wB2J7kMuBe4BKAqtqTZDtwB3AYuKKqHmpvdTmjO6tOBW5sL0nSBA0WFlX1ikdZ9cJH2X4zsHmO+ixw4QK2Jkl6jJbKBW5J0hJmWEiSugwLSVKXYSFJ6jIsJEldg90NJWk49/7CMxe7BS1BX/663YO9t0cWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUtcJExZJ1iW5K8neJFcudj+StJycEGGRZAXwNuDbgfOBVyQ5f3G7kqTl44QIC2AtsLeqPlFV/wtcD6xf5J4kadk4abEbmKeVwH1jy/uAbzh6oySbgE1t8XNJ7ppAb8vBmcCnFruJpSBv3LjYLehYfj6P+LksxLt8xVzFEyUs5voXqGMKVVuALcO3s7wkma2qmcXuQ5qLn8/JOFFOQ+0Dzh1bngb2L1IvkrTsnChh8SFgdZLzkjwR2ADsWOSeJGnZOCFOQ1XV4SQ/ArwXWAFcW1V7Frmt5cRTe1rK/HxOQKqOOfUvSdIXOFFOQ0mSFpFhIUnqMiyWsSSrkty+2H1IWvoMC0lSl2GhFUl+O8meJH+V5NQkP5TkQ0k+kuSdSb4EIMnWJNckeV+STyT5liTXJrkzydZF/j30OJDkyUn+on32bk/yfUnuSfIrSW5tr69s235XkluSfDjJXyc5u9Vfn2Rb+zzfk+SlSX41ye4k70ly8uL+licmw0KrgbdV1QXAvwPfC/xpVX19VT0LuBO4bGz704EXAD8OvBv4DeAC4JlJnj3BvvX4tA7YX1XPqqoLgfe0+merai3wVuA3W+0DwEVV9RxG48X91Nj7PAN4CaMx5N4OvK+qngn8d6vrMTIsdHdV3dbmdwGrgAuT/H2S3cArGYXBEe+u0f3Wu4H7q2p3VT0M7Gn7Sv8fu4EXtSOJb6qq/2j1PxqbfmObnwbe2z6nP8kXfk5vrKrPt/dbwSOhsxs/p18Uw0IPjs0/xOhBza3Aj7S/xH4eeNIc2z981L4Pc4I85Kmlq6r+GVjD6D/1X07yuiOrxjdr07cAb22f01czx+e0/SHz+XrkgTI/p18kw0JzeSpwoJ3bfeViN6PlI8nTgf+qqrcDbwS+rq36vrHpzW3+acC/tHmHAx6YCau5/CxwC/BJRn/hPXVx29Ey8kzg15I8DHweuBx4B3BKklsY/YH7irbt64E/SfIvwAeB8ybf7vLhcB+SlrQk9wAzVeV3ViwiT0NJkro8spAkdXlkIUnqMiwkSV2GhSSpy7CQFkCSz3XWP+YRfttYXC/7/3UmLQzDQpLUZVhICyjJU5LsTPJPbZTT9WOrT2qjoX40yTvGRvNdk+Rvk+xK8t4k5yxS+9KjMiykhfU/wPdU1dcBzwfelCRt3VcDW6rqa4HPAj/chlR5C/CyqloDXAtsXoS+peNyuA9pYQX4pSTfzGjQupXA2W3dfVX1D23+7cBrGI2GeiFwU8uUFcCBiXYszYNhIS2sVwJTwJqq+nwbquLIaKhHPwFbjMJlT1V9I9IS5mkoaWE9DTjYguL5wFeMrfvyJEdC4RWMvrznLmDqSD3JyUkuQFpiDAtpYf0BMJNkltFRxsfG1t0JbEzyUeAM4Jqq+l/gZcCvJPkIcBvw3Mm2LPU5NpQkqcsjC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1PV/s02S8sabWfwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=df['label'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07069445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# Find average number of tokens in all sentences\n",
    "avg_words_len=round(sum([len(i.split()) for i in df['Text']])/len(df['Text']))\n",
    "print(avg_words_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aecc8ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15585\n"
     ]
    }
   ],
   "source": [
    "s = set()\n",
    "for sent in df['Text']:\n",
    "    for word in sent.split():\n",
    "        s.add(word)\n",
    "total_words_length = len(s)\n",
    "print(total_words_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d619a3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4457,)\n",
      "y_train shape: (4457,)\n",
      "X_test shape: (1115,)\n",
      "y_test shape: (1115,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df, X, and y are already defined\n",
    "X, y = np.asarray(df['Text']), np.asarray(df['label_enc'])\n",
    "new_df = pd.DataFrame({'Text': X, 'label': y})\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    new_df['Text'], new_df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Printing the shapes of the resulting sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eca271be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "tfidf_vec = TfidfVectorizer().fit(X_train)\n",
    "X_train_vec,X_test_vec = tfidf_vec.transform(X_train),tfidf_vec.transform(X_test)\n",
    "\n",
    "baseline_model = MultinomialNB()\n",
    "baseline_model.fit(X_train_vec,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70c096f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9623318385650225\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.72      0.84       150\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.86      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the test set\n",
    "y_pred = baseline_model.predict(X_test_vec)\n",
    "\n",
    "# Calculating accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generating classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de5b96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "MAXTOKENS=total_words_length\n",
    "OUTPUTLEN=avg_words_len\n",
    "\n",
    "text_vec = TextVectorization(\n",
    "\tmax_tokens=MAXTOKENS,\n",
    "\tstandardize='lower_and_strip_punctuation',\n",
    "\toutput_mode='int',\n",
    "\toutput_sequence_length=OUTPUTLEN\n",
    ")\n",
    "text_vec.adapt(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d27ae1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(\n",
    "\tinput_dim=MAXTOKENS,\n",
    "\toutput_dim=128,\n",
    "\tembeddings_initializer='uniform',\n",
    "\tinput_length=OUTPUTLEN\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fdc981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_layer = layers.Input(shape=(1,), dtype=tf.string)\n",
    "vec_layer = text_vec(input_layer)\n",
    "embedding_layer_model = embedding_layer(vec_layer)\n",
    "x = layers.GlobalAveragePooling1D()(embedding_layer_model)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_1 = keras.Model(input_layer, output_layer)\n",
    "\n",
    "model_1.compile(optimizer='adam', loss=keras.losses.BinaryCrossentropy(\n",
    "    label_smoothing=0.5), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3109794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def compile_model(model):\n",
    "\t'''\n",
    "\tsimply compile the model with adam optimzer\n",
    "\t'''\n",
    "\tmodel.compile(optimizer=keras.optimizers.Adam(),\n",
    "\t\t\t\tloss=keras.losses.BinaryCrossentropy(),\n",
    "\t\t\t\tmetrics=['accuracy'])\n",
    "\n",
    "def fit_model(model, epochs, X_train=X_train, y_train=y_train,\n",
    "\t\t\tX_test=X_test, y_test=y_test):\n",
    "\t'''\n",
    "\tfit the model with given epochs, train \n",
    "\tand test data\n",
    "\t'''\n",
    "\thistory = model.fit(X_train,\n",
    "\t\t\t\t\t\ty_train,\n",
    "\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\tvalidation_data=(X_test, y_test),\n",
    "\t\t\t\t\t\tvalidation_steps=int(0.2*len(X_test)))\n",
    "\treturn history\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "\t'''\n",
    "\tevaluate the model and returns accuracy, \n",
    "\tprecision, recall and f1-score \n",
    "\t'''\n",
    "\ty_preds = np.round(model.predict(X))\n",
    "\taccuracy = accuracy_score(y, y_preds)\n",
    "\tprecision = precision_score(y, y_preds)\n",
    "\trecall = recall_score(y, y_preds)\n",
    "\tf1 = f1_score(y, y_preds)\n",
    "\n",
    "\tmodel_results_dict = {'accuracy': accuracy,\n",
    "\t\t\t\t\t\t'precision': precision,\n",
    "\t\t\t\t\t\t'recall': recall,\n",
    "\t\t\t\t\t\t'f1-score': f1}\n",
    "\n",
    "\treturn model_results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c14d078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "140/140 [==============================] - 32s 126ms/step - loss: 0.0638 - accuracy: 0.9829 - val_loss: 0.1180 - val_accuracy: 0.9749\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 14s 102ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.1201 - val_accuracy: 0.9821\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 14s 101ms/step - loss: 6.8183e-05 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9821\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 14s 103ms/step - loss: 1.9355e-05 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9821\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 1.2066e-05 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "input_layer = layers.Input(shape=(1,), dtype=tf.string)\n",
    "vec_layer = text_vec(input_layer)\n",
    "embedding_layer_model = embedding_layer(vec_layer)\n",
    "bi_lstm = layers.Bidirectional(layers.LSTM(\n",
    "\t64, activation='tanh', return_sequences=True))(embedding_layer_model)\n",
    "lstm = layers.Bidirectional(layers.LSTM(64))(bi_lstm)\n",
    "flatten = layers.Flatten()(lstm)\n",
    "dropout = layers.Dropout(.1)(flatten)\n",
    "x = layers.Dense(32, activation='relu')(dropout)\n",
    "output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_2 = keras.Model(input_layer, output_layer)\n",
    "\n",
    "compile_model(model_2) # compile the model\n",
    "history_2 = fit_model(model_2, epochs=5) # fit the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d817df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step\n",
      "35/35 [==============================] - 4s 17ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8948/2309667824.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_1_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel_2_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel_3_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m total_results = pd.DataFrame({'MultinomialNB Model':baseline_model_results,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_3' is not defined"
     ]
    }
   ],
   "source": [
    "baseline_model_results = evaluate_model(baseline_model, X_test_vec, y_test)\n",
    "model_1_results = evaluate_model(model_1, X_test, y_test)\n",
    "model_2_results = evaluate_model(model_2, X_test, y_test)\n",
    "model_3_results = evaluate_model(model_3, X_test, y_test)\n",
    "\n",
    "total_results = pd.DataFrame({'MultinomialNB Model':baseline_model_results,\n",
    "\t\t\t\t\t\t\t'Custom-Vec-Embedding Model':model_1_results,\n",
    "\t\t\t\t\t\t\t'Bidirectional-LSTM Model':model_2_results,\n",
    "\t\t\t\t\t\t\t'USE-Transfer learning Model':model_3_results}).transpose()\n",
    "\n",
    "total_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baeec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
